{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6406e19c",
   "metadata": {},
   "source": [
    "# Chapter 1. 한눈에 보는 머신러닝\n",
    "## 1.1. 머신러닝이란?\n",
    "- 명시적인 프로그래밍 없이 컴퓨터가 (데이터에서부터) 학습하는 능력을 갖추게 하는 연구분야\n",
    "- 어떤 작업 T에 대한 컴퓨터프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 컴퓨터 프로그램은 작업 T(training instance)와 성능 측정 P(accuracy)에 대해 경험 E(training data)로 학습한 것\n",
    "\n",
    "## 1.2. 왜 머신러닝을 사용하는가?\n",
    "- 기존 솔루션으로 많은 수동 조정과 규칙이 필요한 문제 : 하나의 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행되도록 함 (자동화)\n",
    "- 전통적인 방식으로 해결방법이 없는 복잡한 문제 : 가장 뛰어난 머신러닝 기법으로 해결방법 찾을 수 있음 (데이터마이닝)\n",
    "- 유동적인 환경 : 새로운 데이터에 적응 (데이터 업데이트시)\n",
    "- 복잡한 문제와 대량의 데이터에서 통찰 얻기 (데이터마이닝 : 머신러닝 알고리즘이 학습한 것을 조사)\n",
    "\n",
    "## 1.3. 애플리케이션 사례\n",
    "- CNN (합성곱 신경망) : 이미지 자동분류, 음성 인식\n",
    "- NLP (자연어처리) : 텍스트분류\n",
    "- RNN (순환 신경망) : 음성인식\n",
    "- Transformer \n",
    "- NLU (자연어 이해) : ex. 챗봇\n",
    "- 회귀작업 : 선형회귀, 다항회귀, SVM, 랜덤 포레스트, 인공신경망 포함\n",
    "- Clusering (군집작업) \n",
    "- Visulization (데이터시각화) cf. 주로 차원축소\n",
    "- RL (강화학습) ex. 알파고"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "deeabaaf",
   "metadata": {},
   "source": [
    "## 1.4. 머신러닝 시스템의 종류  \n",
    "### 1.4.1. 지도학습과 비지도학습\n",
    ": 학습하는 동안의 감독 형태나 정보량  \n",
    "(1) **지도학습** : 알고리즘에 주입하는 훈련 데이터에 레이블 (원하는 답)이 포함\n",
    "- 분류 (classification)\n",
    "- 회귀 (regression) : feature을 이용해 target 수치 예측\n",
    "  - 로지스틱 회귀 : 클래스에 속할 확률을 출력\n",
    "  - 선형 회귀 \n",
    "- k-최근접 이웃 (k-nearest neighbors)\n",
    "- 서포트 벡터 머신 (SVM)\n",
    "- 결정 트리와 랜덤 포레스트\n",
    "- 신경망 (neural networks)\n",
    "\n",
    "(2) **비지도학습** : 훈련 데이터에 레이블이 없음\n",
    "- 군집 (clustering)\n",
    " - k-평균\n",
    " - DBSCAN\n",
    " - 계층군집분석 (HCA)\n",
    " - 이상치 탐지, 특이치 탐지 (outlier / novelty detection)\n",
    " - 원-클래스 (one-class SVM)\n",
    " - 아이솔레이션 포레스트\n",
    "- 시각화와 차원축소 (visualization, dimensionality reduction)\n",
    " - 주성분분석 (PCA)\n",
    " - 커널 PCA\n",
    " - 지역적 선형 임베딩 (LLE)\n",
    " - t-SNE (t-distributed stochastic neighbor embedding) : 의미있는 군집 강조하는 시각화\n",
    "- 연관규칙학습 (association rule learning)\n",
    " - 어프라이어리(apriori)\n",
    " - 이클렛(Eclat)\n",
    "(3) **준지도학습** : 일부만 레이블이 있는 데이터를 다룸\n",
    "- 심층 신뢰 신경망 (DBN) : 비지도학습인 제한된 볼츠만 머신 (RBM)으로 훈련 후 전체 시스템을 지도학습 방식으로 조정\n",
    "(4) **강화 학습** : 에이전트 (학습하는 시스템)가 보상과 벌점을 통해 정책 (최상의 전략)을 스스로 학습  \n",
    "- ex. 딥마인드, 알파고\n",
    "\n",
    "### 1.4.2. 배치 학습과 온라인 학습   \n",
    ": 입력 데이터의 스트림부터 점진적인 학습을 하는지  \n",
    "(1) **배치 학습** : 오프라인 학습, 시스템이 점진적으로 학습할 수 없음\n",
    "- 가용한 데이터를 모두 사용해 훈련시키고 학습한 것을 적용시킴\n",
    "- 새로운 데이터에 대해 학습하려면 전체 데이터를 사용해 새로운 버전을 처음부터 다시 훈련\n",
    "- 많은 컴퓨팅 자원이 필요  \n",
    "\n",
    "(2) **온라인 학습** : 데이터를 순차적으로 한개씩, 혹은 미니배치 단위로 주입하여 시스템을 훈련시킴\n",
    "- 연속적으로 데이터를 받고 변화에 적응시킴\n",
    "- 새로운 데이터 샘플 학습 후 학습이 끝난 데이터를 폐기, 공간 절약 가능\n",
    "- 외부 메모리 학습 : 오프라인으로 실행되는 점진적 학습. 데이터 일부를 읽어들여 훈련하는 과정을 반복\n",
    "- 학습률 : 변화하는 데이터에 얼마나 빠르게 적응할 것인지에 대한 파라미터\n",
    " - 학습률이 높으면 시스템이 데이터에 빠르게 적응 but 예전 데이터를 금방 잊어버림\n",
    " - 학습률이 낮으면 시스템의 관성이 커져 느리게 학습되며 새로운 데이터의 잡음이나 대표성 없는 데이터포인트에 덜 민감해짐\n",
    "- 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 점진적으로 감소 \n",
    "\n",
    "### 1.4.3. 사례 기반 학습과 모델 기반 학습  \n",
    ": 어떻게 일반화 (새로운 데이터에서 좋은 예측을 만드는 것)되는가\n",
    "(1) **사례 기반 학습** \n",
    "- 시스템이 훈련 샘플을 기억함으로써 학습\n",
    "- 유사도 측정 (similarity measure)을 사용해 데이터와 학습된 샘플을 비교하는 식으로 일반화함\n",
    "(2) **모델 기반 학습**\n",
    "- 샘플들의 모델을 만들어 예측에 사용\n",
    "- 모델 파라미터를 조정하여 최상의 성능을 내는 모델 작성\n",
    " - 효용 함수 (적합도 함수) : 모델이 얼마나 좋은지 측정\n",
    " - 비용 함수 : 모델이 얼마나 나쁜지 측정, 주로 사용\n",
    "- => 데이터를 분석 - 모델을 선택 - 훈련 데이터로 모델을 훈련 - 새로운 데이터에 모델을 적용해 예측"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "428a4fea",
   "metadata": {},
   "source": [
    "## 1.5. 머신러닝의 주요 도전 과제\n",
    "### 1.5.1. 충분하지 않은 양의 훈련 데이터\n",
    "### 1.5.2. 대표성 없는 훈련 데이터\n",
    "- 샘플링 편향 : 샘플이 작아 샘플링 잡음 (우연에 의한 대표성 없는 데이터) 발생하거나 표본 추출 방법이 잘못되어 큰 샘플이 대표성을 띠지 못함  \n",
    "\n",
    "### 1.5.3. 낮은 품질의 데이터\n",
    "- 일부 샘플이 이상치인 경우 \n",
    " - 무시하거나 수동으로 잘못된 것을 고치는 것이 좋음\n",
    "- 일부 샘플에 특성 몇 개가 빠져있는 경우 \n",
    " - 해당 특성 혹은 샘플을 무시하거나, 빠진 값을 (평균 등으로) 채우거나, 해당 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지 정해야 함  \n",
    " \n",
    "### 1.5.4. 관련 없는 특성\n",
    "- 특성 선택 : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성 선택\n",
    "- 특성 추출 : 특성을 결합하여 더 유용한 특성을 만듦 (ex. 차원 축소 알고리즘)\n",
    "- 새로운 데이터를 수집해 새 특성을 만듦\n",
    "\n",
    "### 1.5.5. 훈련데이터 과대적합\n",
    "- 모델이 훈련 데이터에 잘 맞지만 일반성이 떨어짐\n",
    "- 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생\n",
    "- 해결 방법\n",
    " - 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화시킴 \n",
    " - 훈련 데이터를 더 많이 모음\n",
    " - 훈련 데이터의 잡음을 줄임 (오류 데이터 수정, 이상치 제거)\n",
    "- 규제 : 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것 (ex. 자유도를 학습 알고리즘에 부여)\n",
    " - 하이퍼파라미터 : 학습하는 동안 적용할 규제의 양 결정, 학습 알고리즘의 파라미터 (훈련중 상수로 남아 있음)\n",
    " \n",
    "### 1.5.6. 훈련데이터 과소적합\n",
    "- 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생\n",
    "- 해결 방법\n",
    " - 모델 파라미터가 더 많은 강력한 모델 선택\n",
    " - 학습 알고리즘에 더 좋은 특성을 제공 (특성 공학)\n",
    " - 모델의 제약을 줄임 (ex. 규제 하이퍼파라미터를 감소시킴)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7df58413",
   "metadata": {},
   "source": [
    "## 1.6. 테스트와 검증\n",
    "- 훈련 데이터를  훈련 세트와 테스트 세트로 나눠 테스트 세트에서 일반화 오차에 대한 추정값을 도출\n",
    " - 일반화 오차 (외부샘플 오차) : 새로운 샘플에 대한 오류 비율\n",
    "- 훈련 세트에서 모델의 오차가 적고 일반화 오차가 높다면 모델이 훈련 데이터에 과대적합되었다는 뜻\n",
    "\n",
    "### 1.6.1. 하이퍼파라미터 튜닝과 모델 선택\n",
    "- 일반화 오차를 테스트 세트에서 여러번 측정시 모델과 하이퍼파라미터가 테스트세트에 최적화된 모델을 만들어, 새로운 데이터에 잘 작동하지 않을 수 있음\n",
    " - 홀드아웃 검증 : 훈련 세트의 일부를 떼어내어 (검증 세트)여러 후보 모델을 평가하고 가장 좋은 하나를 선택\n",
    " - 홀드아웃 검증이 끝나면 최선의 모델을 전체 훈련 세트에서 다시 훈련하여 최종 모델 작성\n",
    " - 최종 모델을 테스트세트에서 평가하여 일반화 오차를 추정\n",
    "- 작은 검증세트 여러개를 사용해 반복적인 교차 검증을 수행하는 것이 좋음\n",
    " - 검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증세트에서 평가 (단, 훈련 시간이 검증 세트의 개수에 비례해 늘어남)\n",
    " \n",
    "(1) 데이터 불일치\n",
    "- 검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 가능한 한 잘 대표해야 함\n",
    "- 검증 세트와 테스트 세트에 데이터가 배타적으로 포함되어야 함\n",
    "- 훈련 개발 세트 : 훈련 사진의 일부를 떼어내어 만든 또 다른 세트. 모델을 훈련 세트에서 훈련한 다음 훈련-개발 세트에서 평가\n",
    " - 해당 모델이 잘 작동하면 훈련 세트에 과대적합한 것이 아님\n",
    " - 해당 모델이 검증 세트에서 나쁜 성능을 낸다면 데이터 불일치가 문제되는 경우\n",
    " - 해당 모델이 잘 작동하지 않는다면 훈련 세트에 과대적합된 것 (모델을 규제하거나 더 많은 훈련데이터를 모으거나 데이터 정제를 시도해야 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c3a286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
